{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Example Detection\n",
    "\n",
    "### Attribute-Steered Model\n",
    "#### Attribute witness extraction\n",
    "* Intersection of __attribute substitution__ and __attribute preservation__.\n",
    "* New model is created by:\n",
    "  * __Neuron weakening:__ weaken the non-witness neurons\n",
    "  * __Neuron strengthening:__ strengthen the witness neurons\n",
    "\n",
    "* Detection (??)\n",
    "  * what does false positive on benign input mean?\n",
    "  * incorrect classification to a class, is it classification with trigger?\n",
    "\n",
    "### Neural network invariant checking\n",
    "* Allow correct behaviors and forbit malicious behaviors (eg: assert certain _behaviors_)\n",
    "* __Value invariants:__ possible value distribution for each neuron\n",
    "* __Provenance invariants:__ possible delta between the values [_pattern_] of two layers of neurons\n",
    "* Examples (??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Sample Defenses\n",
    "### Gradient Masking\n",
    "* Hide or destroy the gradient (so that all gradient based attacks fail)\n",
    "* Defense techniques:\n",
    "  * __Distillation defense:__ changes the scale of last hidden layer\n",
    "  * __Input preprocessing:__ transforms input images by resizing, cropping, discretizing pixels\n",
    "  * __Defense GAN:__ uses GAN to transform perturbed images into clean images\n",
    "\n",
    "#### Evading gradient masking\n",
    "* Approximate gradients\n",
    "* Hiding or breaking gradients makes the loss surface zig-zaggy, when doing backward pass replace function with difficult gradient with one that has nice gradient\n",
    "\n",
    "### Certified Adversarial Robustness\n",
    "* Model gives prediction and a certificate that the prediction is constant (holds) within an $l2$ around the input\n",
    "* Randomized smoothing leads to smoother decision boundaries\n",
    "  * Smooth ùëì into a new classifier $g$ (the ‚Äúsmoothed classifier‚Äù) as follows:\n",
    "$$g(x) = \\text{the most probable prediction by } f \\text{ of random Gaussian corruptions of } x$$\n",
    "* Large random perturbations ‚Äúdrown out‚Äù small adversarial perturbations (??)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
